{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, division\n",
    "\n",
    "from datetime import datetime\n",
    "from email.parser import Parser\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sys import exit\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "def clean_address_list(address_list):\n",
    "    \n",
    "    address_list = address_list.replace(\"\\n\", \"\")\n",
    "    address_list = address_list.replace(\"\\t\", \"\")\n",
    "    address_list = address_list.replace(\" \", \"\")\n",
    "    \n",
    "    address_list = address_list.split(',')\n",
    "    \n",
    "    return address_list\n",
    "\n",
    "\n",
    "def folder_to_df(target_folder):\n",
    "    \"\"\" Load and parse all emails in the specified folder. \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=['to', 'cc', 'bcc', 'from', 'date', 'subject', 'body', 'reply', 'forward'])\n",
    "\n",
    "    for person in glob(\"maildir/*\")[:10]:\n",
    "\n",
    "        for idx, folder in enumerate(glob(\"{}/{}\".format(person, target_folder))):\n",
    "\n",
    "            emails = glob(\"{}/*\".format(folder))\n",
    "\n",
    "            for email in emails:\n",
    "\n",
    "                try:\n",
    "                    content = parse_email(email)\n",
    "                    \n",
    "                    df = df.append(pd.Series(content),ignore_index=True)\n",
    "\n",
    "                except UnicodeDecodeError as err:\n",
    "                    print(err)\n",
    "                    continue\n",
    "                    \n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_body(txt):\n",
    "    \n",
    "    txt = txt.replace('\\n',' ')\n",
    "    txt = txt.replace('\\t',' ')\n",
    "    \n",
    "    return txt\n",
    "\n",
    "\n",
    "def parse_date(datestr):\n",
    "    \n",
    "    return datetime.strptime(datestr[:-5].rstrip(), '%a, %d %b %Y %H:%M:%S %z')\n",
    "\n",
    "\n",
    "def parse_email(message):\n",
    "    \"\"\" Parse a single email. \"\"\"\n",
    "     \n",
    "    try:\n",
    "           \n",
    "        with open(message, 'r') as f:\n",
    "            raw = f.read()\n",
    "        \n",
    "    except UnicodeDecodeError as err:\n",
    "        \n",
    "        print(err)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    txt = Parser().parsestr(raw)\n",
    "    \n",
    "    email = {}\n",
    "\n",
    "    field_to      = txt['to']\n",
    "    field_cc      = txt['cc']\n",
    "    field_bcc     = txt['bcc']\n",
    "    field_from    = txt['from']\n",
    "    field_subject = txt['subject']\n",
    "    field_body    = txt.get_payload()\n",
    "    field_date    = txt['date']\n",
    "    \n",
    "    \n",
    "    if field_from:\n",
    "        \n",
    "        email_from = str(clean_address_list(field_from)[0])\n",
    "        \n",
    "        email['from'] = email_from\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        email['from'] = None\n",
    "        \n",
    "    \n",
    "    if field_to:\n",
    "        \n",
    "        email_to = clean_address_list(field_to)\n",
    "        \n",
    "        email['to'] = email_to\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        email['to'] = None\n",
    "            \n",
    "            \n",
    "    if field_cc:\n",
    "        \n",
    "        email_cc = clean_address_list(field_cc)\n",
    "        \n",
    "        email['cc'] = email_cc\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        email['cc'] = None\n",
    "        \n",
    "            \n",
    "    if field_bcc:\n",
    "        \n",
    "        email_bcc = clean_address_list(field_bcc)\n",
    "        \n",
    "        email['bcc'] = email_bcc\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        email['bcc'] = None\n",
    "        \n",
    "        \n",
    "    if field_date:\n",
    "        \n",
    "        email_date = parse_date(field_date)\n",
    "        \n",
    "        email['date'] = email_date\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        email['date'] = None\n",
    "        \n",
    "        \n",
    "    if field_subject:\n",
    "        \n",
    "        email_subject = field_subject\n",
    "        \n",
    "        email['subject'] = email_subject\n",
    "        \n",
    "        if 'Re:' in email_subject:\n",
    "            \n",
    "            email['reply'] = True\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            email['reply'] = False\n",
    "            \n",
    "            \n",
    "    if field_body:\n",
    "        \n",
    "        email_body = clean_body(field_body)\n",
    "        \n",
    "        email['body'] = email_body\n",
    "        \n",
    "        if '-- Forwarded' in email_body:\n",
    "            \n",
    "            email['forward'] = True\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            email['forward'] = False\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        email['body'] = None\n",
    "            \n",
    "    \n",
    "    return email\n",
    "\n",
    "\n",
    "def subject_analysis(subject):\n",
    "    \n",
    "    # Remove punctuation\n",
    "    subject = subject.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Vader sentiment analysis using a pre-defined lexicon\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "\n",
    "    score = sia.polarity_scores(subject)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = folder_to_df('sent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astros Game\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Ladies and gentlemen of Class #64,  Jeff Skilling has reserved Drayton McLane's suite at Enron Field for the  October 1 (last game of the regular season) Astros game against the  Milwaukee, and he would like you to be his guests.  First pitch is scheduled  at 7:05p.  Please let me know if you are able to join him.  If you do plan to attend,  please let me know the most convenient way to get a ticket to you.  Don't hesitate to call me should you have any questions.  I look forward to a  positive response.  Regards, Sherri Sera Assistant to Jeff Skilling 713.853.5984 713.646.8381 (fax) sherri.sera@enron.com  PS - if there is anyone from Class #64 that is not on this e-mail  distribution, please forward a copy to them.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ladies and gentlemen of Class 64  Jeff Skilling has reserved Drayton McLanes suite at Enron Field for the  October 1 last game of the regular season Astros game against the  Milwaukee and he would like you to be his guests\n",
      "{'neg': 0.0, 'neu': 0.938, 'pos': 0.062, 'compound': 0.3612}\n",
      "\n",
      "\n",
      "First pitch is scheduled  at 705p\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "\n",
      "Please let me know if you are able to join him\n",
      "{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.5423}\n",
      "\n",
      "\n",
      "If you do plan to attend  please let me know the most convenient way to get a ticket to you\n",
      "{'neg': 0.0, 'neu': 0.887, 'pos': 0.113, 'compound': 0.3182}\n",
      "\n",
      "\n",
      "Dont hesitate to call me should you have any questions\n",
      "{'neg': 0.0, 'neu': 0.832, 'pos': 0.168, 'compound': 0.2057}\n",
      "\n",
      "\n",
      "I look forward to a  positive response\n",
      "{'neg': 0.0, 'neu': 0.526, 'pos': 0.474, 'compound': 0.5574}\n",
      "\n",
      "\n",
      "Regards Sherri Sera Assistant to Jeff Skilling 7138535984 7136468381 fax sherriseraenroncom  PS  if there is anyone from Class 64 that is not on this email  distribution please forward a copy to them\n",
      "{'neg': 0.0, 'neu': 0.929, 'pos': 0.071, 'compound': 0.3182}\n"
     ]
    }
   ],
   "source": [
    "def body_analysis(body):\n",
    "    \"\"\" Clean, tokenize, and analyze the body text. \"\"\"\n",
    "    \n",
    "    # Tokenize body content into sentences\n",
    "    sentences = sent_tokenize(body)\n",
    "\n",
    "    # Remove punctuation\n",
    "    sentences = [s.translate(str.maketrans('', '', string.punctuation)) for s in sentences]\n",
    "    \n",
    "    # Vader sentiment analysis using a pre-defined lexicon\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "\n",
    "    for line in sentences:\n",
    "        print('\\n')\n",
    "        print(line)\n",
    "        score = sia.polarity_scores(line)\n",
    "        print(score)\n",
    "    \n",
    "    \n",
    "    filtered_sentences = []\n",
    "    \n",
    "    for s in sentences:\n",
    "        \n",
    "        # Tokenize sentences into words\n",
    "        words = word_tokenize(s)\n",
    "        \n",
    "        # Remove stop words\n",
    "        cleaned = [w for w in words if not w in stop_words] \n",
    "        \n",
    "        filtered_sentences.append(cleaned)\n",
    "        \n",
    "       \n",
    "    return filtered_sentences\n",
    "    \n",
    "    \n",
    "\n",
    "for idx, row in sent_df.iterrows():\n",
    "    \n",
    "    print(row['subject'])\n",
    "    subject_analysis(row['subject'])\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    # Get body text\n",
    "    text = row['body']\n",
    "    \n",
    "    print(text)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    body_analysis(row['body'])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
